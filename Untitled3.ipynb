{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10adf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a214eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_dir = os.path.join('./env_site/horse-or-human/horses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb2025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_human_dir = os.path.join('./env_site/horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d5f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse43-5.png', 'horse06-5.png', 'horse20-6.png', 'horse04-7.png', 'horse41-7.png', 'horse22-4.png', 'horse19-2.png', 'horse24-2.png', 'horse37-8.png', 'horse02-1.png']\n",
      "['human17-22.png', 'human10-17.png', 'human10-03.png', 'human07-27.png', 'human09-22.png', 'human05-22.png', 'human02-03.png', 'human02-17.png', 'human15-27.png', 'human12-12.png']\n"
     ]
    }
   ],
   "source": [
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c91bcb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training horse images: 500\n",
      "total training human images: 527\n"
     ]
    }
   ],
   "source": [
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images:', len(os.listdir(train_human_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0017571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4a07a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 09:40:07.638208: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-04 09:40:07.639106: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9deaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0edf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa9e800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './env_site/horse-or-human/', \n",
    "        target_size=(300, 300),\n",
    "        batch_size=128,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91372608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 09:42:57.216632: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-04 09:42:57.943111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 17s 1s/step - loss: 3.7782 - accuracy: 0.4772\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.7289 - accuracy: 0.5573\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.6682 - accuracy: 0.6474\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.5800 - accuracy: 0.8331\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.5586 - accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1756 - accuracy: 0.9344\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.3580 - accuracy: 0.8843\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 10s 1s/step - loss: 0.1692 - accuracy: 0.9410\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1531 - accuracy: 0.9533\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 2.0759 - accuracy: 0.8398\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.1191 - accuracy: 0.9555\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0674 - accuracy: 0.9700\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.0710 - accuracy: 0.9733\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1230 - accuracy: 0.9544\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.0383 - accuracy: 0.9855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae649f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.jpeg', '4.jpeg', '2.jpeg', '3.jpeg']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 09:48:44.154563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[0.00011409]\n",
      "1.jpeg is a horse\n",
      "\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[0.9983354]\n",
      "4.jpeg is a human\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[0.85442877]\n",
      "2.jpeg is a human\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[0.18713818]\n",
      "3.jpeg is a horse\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "images = os.listdir(\"./env_site/images\")\n",
    "\n",
    "print(images)\n",
    "\n",
    "for i in images:\n",
    "    print()\n",
    "    path = './env_site/images/' + i\n",
    "    img = load_img(path, target_size=(300, 300))\n",
    "    x = img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(i + \" is a human\")\n",
    "    else:\n",
    "        print(i + \" is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3e0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepL)",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
